{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29d2d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "### please specify your input path here\n",
    "PROJECT_FOLDER = \"YOUR_PROJECT_FOLDER\" # parent folder of the input images\n",
    "IMAGE_DATA_FOLDER = PROJECT_FOLDER + \"images/\" # folder of the input images\n",
    "INPUT_TEST_CSV_FILE = \"YOUR_TEST_FILE\" # csv file list locations / paths to test cases (dicom)\n",
    "OUTPUT_FILE = \"YOUR_OUTPUT\" # in csv format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19259352",
   "metadata": {
    "papermill": {
     "duration": 0.005527,
     "end_time": "2022-10-23T09:35:44.341257",
     "exception": false,
     "start_time": "2022-10-23T09:35:44.335730",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fe51571",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 398.428808,
     "end_time": "2022-10-23T09:42:22.774671",
     "exception": false,
     "start_time": "2022-10-23T09:35:44.345863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !cp -r /kaggle/input/python-packages /kaggle/working\n",
    "# !pip install -q /kaggle/working/python-packages/pylibjpeg_libjpeg-1.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "# !pip install -q /kaggle/working/python-packages/pylibjpeg_openjpeg-1.2.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "# !pip install -q /kaggle/working/python-packages/pylibjpeg_rle-1.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "# !pip install -q /kaggle/working/python-packages/iopath-0.1.9-py3-none-any.whl\n",
    "# !pip install -q /kaggle/working/python-packages/av-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "# !pip install -q /kaggle/working/python-packages/fvcore-0.1.5.post20220512/\n",
    "# !pip install -q /kaggle/working/python-packages/parameterized-0.8.1-py2.py3-none-any.whl\n",
    "# !pip install -q /kaggle/working/python-packages/pytorchvideo-0.1.5/\n",
    "# !pip install -q /kaggle/working/python-packages/timm-0.6.7-py3-none-any.whl\n",
    "# !pip install -q /kaggle/working/python-packages/antlr4-python3-runtime-4.9.3/\n",
    "# !pip install -q /kaggle/working/python-packages/omegaconf-2.2.2-py3-none-any.whl\n",
    "# !pip install -q /kaggle/working/python-packages/monai-0.8.1-202202162213-py3-none-any.whl\n",
    "#\n",
    "# !cp /kaggle/input/gdcm-conda-install/gdcm.tar /kaggle/working/\n",
    "# !tar -xzvf gdcm.tar\n",
    "# !conda install --offline /kaggle/working/gdcm/gdcm-2.8.9-py37h71b2a6d_0.tar.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d18c8d",
   "metadata": {
    "papermill": {
     "duration": 0.005759,
     "end_time": "2022-10-23T09:42:22.788360",
     "exception": false,
     "start_time": "2022-10-23T09:42:22.782601",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264ea9af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T22:04:54.219667Z",
     "start_time": "2023-07-12T22:04:49.047450Z"
    },
    "papermill": {
     "duration": 8.807254,
     "end_time": "2022-10-23T09:42:31.601469",
     "exception": false,
     "start_time": "2022-10-23T09:42:22.794215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./rsna-cspine-src/\")\n",
    "sys.path.append(\"./rsna-cspine-src/skp\")\n",
    "\n",
    "\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "from collections import defaultdict\n",
    "from omegaconf import OmegaConf\n",
    "from scipy.ndimage.interpolation import zoom \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from skp import builder\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6a5baf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T22:07:35.146598Z",
     "start_time": "2023-07-12T22:07:35.140883Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb562ad",
   "metadata": {
    "papermill": {
     "duration": 0.005833,
     "end_time": "2022-10-23T09:42:31.613873",
     "exception": false,
     "start_time": "2022-10-23T09:42:31.608040",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83168dd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T22:08:13.542201Z",
     "start_time": "2023-07-12T22:08:13.537626Z"
    },
    "papermill": {
     "duration": 0.036886,
     "end_time": "2022-10-23T09:42:31.656998",
     "exception": false,
     "start_time": "2022-10-23T09:42:31.620112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def window(x, WL, WW):\n",
    "    upper, lower = WL+WW//2, WL-WW//2\n",
    "    x = np.clip(x, lower, upper)\n",
    "    x = x - lower\n",
    "    x = x / (upper - lower)\n",
    "    x = x * 255\n",
    "    x = x.astype('uint8')\n",
    "    return x\n",
    "\n",
    "\n",
    "def load_dicom_volume(dicom_folder):\n",
    "    dicom_files = glob.glob(osp.join(dicom_folder, \"*.dcm\"))\n",
    "    dicoms = [pydicom.dcmread(_) for _ in dicom_files]\n",
    "    z_positions = [float(_.ImagePositionPatient[2]) for _ in dicoms]\n",
    "    dicom_arrays = [_.pixel_array.astype(\"float32\") for _ in dicoms]\n",
    "    rescale_slope = float(dicoms[0].RescaleSlope)\n",
    "    rescale_intercept = float(dicoms[0].RescaleIntercept)\n",
    "    del dicoms \n",
    "    \n",
    "    # Deal with potential scenario where not all arrays are the same shape\n",
    "    # This assumes that all arrays have the same number of dimensions (2)\n",
    "    array_shapes = np.vstack([_.shape for _ in dicom_arrays])\n",
    "    h, w = np.median(array_shapes[:,0]), np.median(array_shapes[:,1])\n",
    "    for ind, arr in enumerate(dicom_arrays):\n",
    "        if arr.shape[0] != h or arr.shape[1] != w:\n",
    "            print(\"Mismatched shape, resizing ...\")\n",
    "            scale_h, scale_w = float(h) / arr.shape[0], float(w) / arr.shape[1]\n",
    "            arr = zoom(arr, [scale_h, scale_w], order=1, prefilter=False)\n",
    "            dicom_arrays[ind] = arr\n",
    "    \n",
    "    array = np.stack(dicom_arrays)\n",
    "    del dicom_arrays \n",
    "    array = rescale_slope * array + rescale_intercept\n",
    "    array = window(array, WL=400, WW=2500)\n",
    "    \n",
    "    # Sort in DESCENDING order by z-position\n",
    "    array = array[np.argsort(z_positions)[::-1]]\n",
    "    return array\n",
    "\n",
    "\n",
    "def plot_volume(array, skip=10, sagittal=False):\n",
    "    length = array.shape[2] if sagittal else array.shape[0]\n",
    "    for i in range(0, length, skip):\n",
    "        image = array[..., i] if sagittal else array[i]\n",
    "        if np.sum(image) == 0:\n",
    "            continue\n",
    "        plt.imshow(image, cmap=\"gray\")\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "def rescale(x):\n",
    "    # Rescale to [-1, 1]\n",
    "    x = x / x.max()\n",
    "    x = x - 0.5\n",
    "    x = x * 2\n",
    "    return x\n",
    "\n",
    "\n",
    "def unscale(x):\n",
    "    x = x + 1\n",
    "    x = x * 255 / 2\n",
    "    return x\n",
    "\n",
    "\n",
    "def load_models(config_file, checkpoint_folder, model_type=\"classification\", cuda=torch.cuda.is_available(), load_indices=None):\n",
    "    assert model_type in [\"classification\", \"segmentation\", \"sequence\", \"tdcnn\"]\n",
    "    config = OmegaConf.load(config_file)\n",
    "    if model_type == \"segmentation\":\n",
    "        config.model.params.encoder_params.pretrained = False\n",
    "    elif model_type == \"classification\":\n",
    "        config.model.params.pretrained = False\n",
    "    elif model_type == \"tdcnn\":\n",
    "        config.model.params.cnn_params.pretrained = False \n",
    "    checkpoints = np.sort(glob.glob(osp.join(checkpoint_folder, \"*\")))\n",
    "    if isinstance(load_indices, (list, tuple)):\n",
    "        load_indices = list(load_indices)\n",
    "        checkpoints = checkpoints[load_indices]\n",
    "    models = []\n",
    "    for each_checkpoint in checkpoints:\n",
    "        _config = config.copy()\n",
    "        _config.model.load_pretrained = str(each_checkpoint)\n",
    "        _model = builder.build_model(_config).eval()\n",
    "        if cuda:\n",
    "            _model = _model.to(device)\n",
    "        models.append(_model)\n",
    "    return models \n",
    "\n",
    "            \n",
    "def get_cervical_spine_coordinates(volume, inference_shape, segmentation_models, threshold, adjustment, uid):\n",
    "    orig_shape = volume.shape[2:]\n",
    "    volume = F.interpolate(volume, size=inference_shape, mode=\"nearest\")\n",
    "    segmentation = torch.sigmoid(torch.cat([seg_model(volume.to(device)) for seg_model in segmentation_models])).mean(0)\n",
    "    cspine_coords = {}\n",
    "    for level in range(7):\n",
    "        coords = torch.stack(torch.where(segmentation[level] >= threshold)).cpu().numpy()\n",
    "        coords[0] = coords[0] * orig_shape[0] / inference_shape[0] \n",
    "        coords[1] = coords[1] * orig_shape[1] / inference_shape[1] \n",
    "        coords[2] = coords[2] * orig_shape[2] / inference_shape[2] \n",
    "        adjusted_threshold = threshold\n",
    "        need_refine = False\n",
    "        while coords.shape[1] == 0 and adjusted_threshold > adjustment:\n",
    "            print(f\"uid:{uid} C{level+1} not found, lowering threshold to {adjusted_threshold - adjustment:0.1f} ...\")\n",
    "            adjusted_threshold -= adjustment\n",
    "            adjusted_threshold = np.round(adjusted_threshold, 1)\n",
    "            coords = torch.stack(torch.where(segmentation[level] >= threshold)).cpu().numpy()\n",
    "        if coords.shape[1] == 0:\n",
    "            print(f\"uid:{uid} Segmentation for C{level+1} failed !\")\n",
    "            cspine_coords[level] = None\n",
    "        else:\n",
    "            cspine_coords[level] = (coords[0].min(), coords[0].max(), coords[1].min(), coords[1].max(), coords[2].min(), coords[2].max())\n",
    "    return cspine_coords\n",
    "\n",
    "\n",
    "def center_crop(x, crop_size):\n",
    "    h, w = crop_size\n",
    "    orig_h, orig_w = x.shape[-2], x.shape[-1]\n",
    "    diff_h, diff_w = (orig_h - h) // 2, (orig_w - w) // 2\n",
    "    return x[..., diff_h:diff_h+h, diff_w:diff_w+w]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede55520",
   "metadata": {
    "papermill": {
     "duration": 0.006123,
     "end_time": "2022-10-23T09:42:31.669268",
     "exception": false,
     "start_time": "2022-10-23T09:42:31.663145",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40c996b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T22:08:28.131372Z",
     "start_time": "2023-07-12T22:08:16.172102Z"
    },
    "papermill": {
     "duration": 44.965253,
     "end_time": "2022-10-23T09:43:16.644500",
     "exception": false,
     "start_time": "2022-10-23T09:42:31.679247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model <NetSegment3D> ...\n",
      "Confirmed encoder output stride 16 !\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-pseudoseg000/fold0.ckpt\n",
      "Creating model <NetSegment3D> ...\n",
      "Confirmed encoder output stride 16 !\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-pseudoseg000/fold1.ckpt\n",
      "Creating model <NetSegment3D> ...\n",
      "Confirmed encoder output stride 16 !\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-pseudoseg000/fold2.ckpt\n",
      "Creating model <NetSegment3D> ...\n",
      "Confirmed encoder output stride 16 !\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-pseudoseg000/fold3.ckpt\n",
      "Creating model <NetSegment3D> ...\n",
      "Confirmed encoder output stride 16 !\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-pseudoseg000/fold4.ckpt\n",
      "Creating model <Net3D> ...\n",
      "  Using backbone <x3d_l> ...\n",
      "  Pretrained : False\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-chunk000/fold0.ckpt\n",
      "Creating model <Net3D> ...\n",
      "  Using backbone <x3d_l> ...\n",
      "  Pretrained : False\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-chunk000/fold1.ckpt\n",
      "Creating model <Net3D> ...\n",
      "  Using backbone <x3d_l> ...\n",
      "  Pretrained : False\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-chunk000/fold2.ckpt\n",
      "Creating model <Net3D> ...\n",
      "  Using backbone <x3d_l> ...\n",
      "  Pretrained : False\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-chunk000/fold3.ckpt\n",
      "Creating model <Net3D> ...\n",
      "  Using backbone <x3d_l> ...\n",
      "  Pretrained : False\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-chunk000/fold4.ckpt\n",
      "Creating model <DualTransformer> ...\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-chunkseq003/fold0.ckpt\n",
      "Creating model <DualTransformer> ...\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-chunkseq003/fold1.ckpt\n",
      "Creating model <DualTransformer> ...\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-chunkseq003/fold2.ckpt\n",
      "Creating model <DualTransformer> ...\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-chunkseq003/fold3.ckpt\n",
      "Creating model <DualTransformer> ...\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-chunkseq003/fold4.ckpt\n",
      "Creating model <TDCNN> ...\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-chunk101/fold0.ckpt\n",
      "Creating model <TDCNN> ...\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-chunk101/fold1.ckpt\n",
      "Creating model <TDCNN> ...\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-chunk101/fold2.ckpt\n",
      "Creating model <TDCNN> ...\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-chunk101/fold3.ckpt\n",
      "Creating model <TDCNN> ...\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-chunk101/fold4.ckpt\n",
      "Creating model <DualTransformer> ...\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-chunkseq005/fold0.ckpt\n",
      "Creating model <DualTransformer> ...\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-chunkseq005/fold1.ckpt\n",
      "Creating model <DualTransformer> ...\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-chunkseq005/fold2.ckpt\n",
      "Creating model <DualTransformer> ...\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-chunkseq005/fold3.ckpt\n",
      "Creating model <DualTransformer> ...\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-chunkseq005/fold4.ckpt\n",
      "Creating model <DualTransformer> ...\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-chunkseq006/fold0.ckpt\n",
      "Creating model <DualTransformer> ...\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-chunkseq006/fold1.ckpt\n",
      "Creating model <DualTransformer> ...\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-chunkseq006/fold2.ckpt\n",
      "Creating model <DualTransformer> ...\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-chunkseq006/fold3.ckpt\n",
      "Creating model <DualTransformer> ...\n",
      "  Loading pretrained checkpoint from ./rsna-cspine-chunkseq006/fold4.ckpt\n"
     ]
    }
   ],
   "source": [
    "cspine_segmentation_models = load_models(\"./rsna-cspine-src/configs/seg/pseudoseg000.yaml\",\n",
    "                                         \"./rsna-cspine-pseudoseg000/\",\n",
    "                                         model_type=\"segmentation\",\n",
    "                                         load_indices=[0, 1, 2, 3, 4])\n",
    "\n",
    "\n",
    "feature_extractors_3d = load_models(\"./rsna-cspine-src/configs/chunk/chunk000.yaml\",\n",
    "                                    \"./rsna-cspine-chunk000/\",\n",
    "                                    load_indices=[0, 1, 2, 3, 4])\n",
    "\n",
    "chunk_sequence_models = load_models(\"./rsna-cspine-src/configs/chunkseq/chunkseq003.yaml\",\n",
    "                                    \"./rsna-cspine-chunkseq003/\",\n",
    "                                    model_type=\"sequence\",\n",
    "                                    load_indices=[0, 1, 2, 3, 4])\n",
    "\n",
    "\n",
    "feature_extractors_2d = load_models(\"./rsna-cspine-src/configs/chunk/chunk101.yaml\",\n",
    "                                    \"./rsna-cspine-chunk101/\",\n",
    "                                    model_type=\"tdcnn\",\n",
    "                                    load_indices=[0, 1, 2, 3, 4])\n",
    "\n",
    "slice_sequence_models = load_models(\"./rsna-cspine-src/configs/chunkseq/chunkseq005.yaml\",\n",
    "                                    \"./rsna-cspine-chunkseq005/\",\n",
    "                                    model_type=\"sequence\",\n",
    "                                    load_indices=[0, 1, 2, 3, 4])\n",
    "\n",
    "\n",
    "fused_sequence_models = load_models(\"./rsna-cspine-src/configs/chunkseq/chunkseq006.yaml\",\n",
    "                                    \"./rsna-cspine-chunkseq006/\",\n",
    "                                    model_type=\"sequence\",\n",
    "                                    load_indices=[0, 1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1635590b-8504-4d20-9490-95bbe8382e29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape: (5161, 3)\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(INPUT_TEST_CSV_FILE)\n",
    "\n",
    "print('test shape:', test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20f90d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T22:13:17.472759Z",
     "start_time": "2023-07-12T22:08:30.454708Z"
    },
    "papermill": {
     "duration": 67.376673,
     "end_time": "2022-10-23T09:44:24.030297",
     "exception": false,
     "start_time": "2022-10-23T09:43:16.653624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 175/5161 [22:01<8:03:58,  5.82s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uid:1.2.826.0.1.3680043.10.474.634358.865657 C6 not found, lowering threshold to 0.3 ...\n",
      "uid:1.2.826.0.1.3680043.10.474.634358.865657 C6 not found, lowering threshold to 0.2 ...\n",
      "uid:1.2.826.0.1.3680043.10.474.634358.865657 C6 not found, lowering threshold to 0.1 ...\n",
      "uid:1.2.826.0.1.3680043.10.474.634358.865657 Segmentation for C6 failed !\n",
      "uid:1.2.826.0.1.3680043.10.474.634358.865657 C7 not found, lowering threshold to 0.3 ...\n",
      "uid:1.2.826.0.1.3680043.10.474.634358.865657 C7 not found, lowering threshold to 0.2 ...\n",
      "uid:1.2.826.0.1.3680043.10.474.634358.865657 C7 not found, lowering threshold to 0.1 ...\n",
      "uid:1.2.826.0.1.3680043.10.474.634358.865657 Segmentation for C7 failed !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 176/5161 [22:06<7:19:53,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C6 not found ... Using 0-vector ...\n",
      "C7 not found ... Using 0-vector ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 193/5161 [23:55<8:46:46,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uid:1.2.826.0.1.3680043.10.474.634358.874233 C5 not found, lowering threshold to 0.3 ...\n",
      "uid:1.2.826.0.1.3680043.10.474.634358.874233 C5 not found, lowering threshold to 0.2 ...\n",
      "uid:1.2.826.0.1.3680043.10.474.634358.874233 C5 not found, lowering threshold to 0.1 ...\n",
      "uid:1.2.826.0.1.3680043.10.474.634358.874233 Segmentation for C5 failed !\n",
      "C5 not found ... Using 0-vector ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 208/5161 [25:38<9:05:41,  6.61s/it] "
     ]
    }
   ],
   "source": [
    "threshold = 0.4\n",
    "adjustment = 0.1\n",
    "segmentation_inference_size = (192, 192, 192)\n",
    "chunk_inference_size = (64, 288, 288)\n",
    "slice_inference_size = (32, 288, 288)\n",
    "\n",
    "chunk_prediction_dict, slice_prediction_dict, fused_prediction_dict = {}, {}, {}\n",
    "for index, row in tqdm(test_df.iterrows(), total=test_df.shape[0]):\n",
    "    uid = row['StudyInstanceUID']\n",
    "    image_folder = row['image_folder']\n",
    "    X = load_dicom_volume(image_folder)\n",
    "    X = rescale(X)\n",
    "    X = torch.from_numpy(X).float().unsqueeze(0).unsqueeze(0)\n",
    "    # X.shape = (1, 1, num_images, height, width)\n",
    "\n",
    "    cspine_coords = get_cervical_spine_coordinates(X, segmentation_inference_size, cspine_segmentation_models, threshold, adjustment, uid)\n",
    "    chunk_features = defaultdict(list)\n",
    "    slice_features = defaultdict(list)\n",
    "\n",
    "    for level, coords in cspine_coords.items():\n",
    "        if not isinstance(coords, tuple):\n",
    "            print(f\"C{level+1} not found ... Using 0-vector ...\")\n",
    "            for fold, model in enumerate(feature_extractors_3d):\n",
    "                chunk_features[fold].append(torch.zeros((1, 432)).float().to(device))\n",
    "            for fold, model in enumerate(feature_extractors_2d):\n",
    "                slice_features[fold].append(torch.zeros((1, 256)).float().to(device))\n",
    "        else:\n",
    "            x1, x2, y1, y2, z1, z2 = coords\n",
    "            if ((z2-z1==0) or (y2-y1==0) or (x2-x1==0)):\n",
    "                print(f\"C{level+1} has 0 shape ... Using 0-vector ...\")\n",
    "                for fold, model in enumerate(feature_extractors_3d):\n",
    "                    chunk_features[fold].append(torch.zeros((1, 432)).float().to(device))\n",
    "                for fold, model in enumerate(feature_extractors_2d):\n",
    "                    slice_features[fold].append(torch.zeros((1, 256)).float().to(device))\n",
    "                continue\n",
    "            orig_chunk = X[:, :, x1:x2, y1:y2, z1:z2]\n",
    "            \n",
    "            chunk = F.interpolate(orig_chunk, size=chunk_inference_size, mode=\"trilinear\")\n",
    "            for fold, model in enumerate(feature_extractors_3d):\n",
    "                chunk_features[fold].append(model.extract_features(chunk.to(device)))\n",
    "\n",
    "            chunk = F.interpolate(orig_chunk, size=slice_inference_size, mode=\"trilinear\")\n",
    "            for fold, model in enumerate(feature_extractors_2d):\n",
    "                slice_features[fold].append(model.extract_features(chunk.to(device)))\n",
    "\n",
    "         \n",
    "\n",
    "    for fold, features in chunk_features.items():\n",
    "        chunk_features[fold] = (torch.cat(features).unsqueeze(0).to(device), torch.ones((1, 7)).float().to(device))\n",
    "    for fold, features in slice_features.items():\n",
    "        slice_features[fold] = (torch.cat(features).unsqueeze(0).to(device), torch.ones((1, 7)).float().to(device))\n",
    "        \n",
    "    fused_features = {}\n",
    "    for fold in [*chunk_features]:\n",
    "        fused_features[fold] = (torch.cat([chunk_features[fold][0], slice_features[fold][0]], dim=-1), torch.ones((1, 7)).float().to(device))\n",
    "        \n",
    "    chunk_pred_list = []\n",
    "    for fold, model in enumerate(chunk_sequence_models):\n",
    "        chunk_pred_list.append(torch.sigmoid(model(chunk_features[fold])).cpu().numpy())\n",
    "    chunk_prediction_dict[uid] = np.mean(np.stack(chunk_pred_list, axis=0), axis=0)\n",
    "    slice_pred_list = []\n",
    "    for fold, model in enumerate(slice_sequence_models):\n",
    "        slice_pred_list.append(torch.sigmoid(model(slice_features[fold])).cpu().numpy())\n",
    "    slice_prediction_dict[uid] = np.mean(np.stack(slice_pred_list, axis=0), axis=0)\n",
    "    fused_pred_list = []\n",
    "    for fold, model in enumerate(fused_sequence_models):\n",
    "        fused_pred_list.append(torch.sigmoid(model(fused_features[fold])).cpu().numpy())\n",
    "    fused_prediction_dict[uid] = np.mean(np.stack(fused_pred_list, axis=0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fac54c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T22:13:30.106830Z",
     "start_time": "2023-07-12T22:13:30.103016Z"
    },
    "papermill": {
     "duration": 0.021751,
     "end_time": "2022-10-23T09:44:24.063494",
     "exception": false,
     "start_time": "2022-10-23T09:44:24.041743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def competition_metric(p, t):\n",
    "#     # p.shape = t.shape = (N, 8)\n",
    "#     p = torch.from_numpy(p).float()\n",
    "#     t = torch.from_numpy(t).float()\n",
    "#     loss_matrix = F.binary_cross_entropy(p, t, reduction=\"none\")\n",
    "#     # loss_matrix.shape = (N, 8)\n",
    "#     columnwise_losses = []\n",
    "#     for col in range(loss_matrix.shape[1]):\n",
    "#         weights = t[:, col] + 1 # positives are weighted 2x\n",
    "#         columnwise_losses.append(((loss_matrix[:, col] * weights).sum() / weights.sum()).item())\n",
    "#     columnwise_losses[-1] *= 7.0\n",
    "#     return np.sum(columnwise_losses) / 14.0\n",
    "\n",
    "\n",
    "# def auc(p, t):\n",
    "#     if len(np.unique(t)) == 1:\n",
    "#         return 0.5\n",
    "#     return roc_auc_score(t, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baded04a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T22:13:31.041026Z",
     "start_time": "2023-07-12T22:13:31.034589Z"
    },
    "papermill": {
     "duration": 0.019083,
     "end_time": "2022-10-23T09:44:24.091945",
     "exception": false,
     "start_time": "2022-10-23T09:44:24.072862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# study_id_list = []\n",
    "# predictions_list = []\n",
    "\n",
    "# for study_id, pred in chunk_prediction_dict.items():\n",
    "#     study_id_list.append(study_id.split(\"/\")[-1])\n",
    "#     predictions_list.append(pred)\n",
    "    \n",
    "# pred_df = pd.DataFrame(np.concatenate(predictions_list))\n",
    "# pred_df.columns = [f\"C{_+1}_pred\" for _ in range(7)] + [\"patient_overall_pred\"]\n",
    "# pred_df[\"StudyInstanceUID\"] = study_id_list\n",
    "\n",
    "# train_df = pd.read_csv(\"./rsna-2022-cervical-spine-fracture-detection/train.csv\")\n",
    "# pred_df = pred_df.merge(train_df, on=\"StudyInstanceUID\")\n",
    "# pred_df\n",
    "\n",
    "# t_columns = [f\"C{i+1}\" for i in range(7)] + [\"patient_overall\"]\n",
    "# p_columns = [c + \"_pred\" for c in t_columns]\n",
    "\n",
    "# print(f\"COMP. METRIC : {competition_metric(pred_df[p_columns].values, pred_df[t_columns].values):0.3f}\")\n",
    "\n",
    "# for i in range(len(t_columns)):\n",
    "#     prefix = \"AUC[overall] : \" if i == len(t_columns) - 1 else f\"AUC[C{i+1}]      : \"\n",
    "#     p = pred_df[p_columns[i]].values\n",
    "#     t = pred_df[t_columns[i]].values\n",
    "#     print(f\"{prefix}{auc(p, t):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04d18f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T22:13:31.339012Z",
     "start_time": "2023-07-12T22:13:31.334818Z"
    },
    "papermill": {
     "duration": 0.017123,
     "end_time": "2022-10-23T09:44:24.118852",
     "exception": false,
     "start_time": "2022-10-23T09:44:24.101729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# study_id_list = []\n",
    "# predictions_list = []\n",
    "\n",
    "# for study_id, pred in slice_prediction_dict.items():\n",
    "#     study_id_list.append(study_id.split(\"/\")[-1])\n",
    "#     predictions_list.append(pred)\n",
    "    \n",
    "# pred_df = pd.DataFrame(np.concatenate(predictions_list))\n",
    "# pred_df.columns = [f\"C{_+1}_pred\" for _ in range(7)] + [\"patient_overall_pred\"]\n",
    "# pred_df[\"StudyInstanceUID\"] = study_id_list\n",
    "\n",
    "# train_df = pd.read_csv(\"./rsna-2022-cervical-spine-fracture-detection/train.csv\")\n",
    "# pred_df = pred_df.merge(train_df, on=\"StudyInstanceUID\")\n",
    "# pred_df\n",
    "\n",
    "# t_columns = [f\"C{i+1}\" for i in range(7)] + [\"patient_overall\"]\n",
    "# p_columns = [c + \"_pred\" for c in t_columns]\n",
    "\n",
    "# print(f\"COMP. METRIC : {competition_metric(pred_df[p_columns].values, pred_df[t_columns].values):0.3f}\")\n",
    "\n",
    "# for i in range(len(t_columns)):\n",
    "#     prefix = \"AUC[overall] : \" if i == len(t_columns) - 1 else f\"AUC[C{i+1}]      : \"\n",
    "#     p = pred_df[p_columns[i]].values\n",
    "#     t = pred_df[t_columns[i]].values\n",
    "#     print(f\"{prefix}{auc(p, t):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dac429",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T22:13:31.592609Z",
     "start_time": "2023-07-12T22:13:31.589060Z"
    },
    "papermill": {
     "duration": 0.017263,
     "end_time": "2022-10-23T09:44:24.145276",
     "exception": false,
     "start_time": "2022-10-23T09:44:24.128013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# study_id_list = []\n",
    "# predictions_list = []\n",
    "\n",
    "# for study_id, pred in fused_prediction_dict.items():\n",
    "#     study_id_list.append(study_id.split(\"/\")[-1])\n",
    "#     predictions_list.append(pred)\n",
    "    \n",
    "# pred_df = pd.DataFrame(np.concatenate(predictions_list))\n",
    "# pred_df.columns = [f\"C{_+1}_pred\" for _ in range(7)] + [\"patient_overall_pred\"]\n",
    "# pred_df[\"StudyInstanceUID\"] = study_id_list\n",
    "\n",
    "# train_df = pd.read_csv(\"./rsna-2022-cervical-spine-fracture-detection/train.csv\")\n",
    "# pred_df = pred_df.merge(train_df, on=\"StudyInstanceUID\")\n",
    "# pred_df\n",
    "\n",
    "# t_columns = [f\"C{i+1}\" for i in range(7)] + [\"patient_overall\"]\n",
    "# p_columns = [c + \"_pred\" for c in t_columns]\n",
    "\n",
    "# print(f\"COMP. METRIC : {competition_metric(pred_df[p_columns].values, pred_df[t_columns].values):0.3f}\")\n",
    "\n",
    "# for i in range(len(t_columns)):\n",
    "#     prefix = \"AUC[overall] : \" if i == len(t_columns) - 1 else f\"AUC[C{i+1}]      : \"\n",
    "#     p = pred_df[p_columns[i]].values\n",
    "#     t = pred_df[t_columns[i]].values\n",
    "#     print(f\"{prefix}{auc(p, t):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1276ed99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T22:13:31.968296Z",
     "start_time": "2023-07-12T22:13:31.963864Z"
    },
    "papermill": {
     "duration": 0.016773,
     "end_time": "2022-10-23T09:44:24.171074",
     "exception": false,
     "start_time": "2022-10-23T09:44:24.154301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# study_id_list = []\n",
    "# predictions_list = []\n",
    "\n",
    "# chunk_weight, chunk_slice_weight, slice_weight = 0.35, 0.35, 0.3\n",
    "# assert chunk_weight + chunk_slice_weight + slice_weight == 1\n",
    "# for study_id in [*slice_prediction_dict]:\n",
    "#     study_id_list.append(study_id.split(\"/\")[-1])\n",
    "#     predictions_list.append(chunk_weight * chunk_prediction_dict[study_id] + \\\n",
    "#                             chunk_slice_weight * chunk_slice_prediction_dict[study_id] + \\\n",
    "#                             slice_weight * slice_prediction_dict[study_id])\n",
    "\n",
    "# pred_df = pd.DataFrame(np.concatenate(predictions_list))\n",
    "# pred_df.columns = [f\"C{_+1}_pred\" for _ in range(7)] + [\"patient_overall_pred\"]\n",
    "# pred_df[\"StudyInstanceUID\"] = study_id_list\n",
    "\n",
    "# train_df = pd.read_csv(\"./rsna-2022-cervical-spine-fracture-detection/train.csv\")\n",
    "# pred_df = pred_df.merge(train_df, on=\"StudyInstanceUID\")\n",
    "# pred_df\n",
    "\n",
    "# t_columns = [f\"C{i+1}\" for i in range(7)] + [\"patient_overall\"]\n",
    "# p_columns = [c + \"_pred\" for c in t_columns]\n",
    "\n",
    "# print(f\"COMP. METRIC : {competition_metric(pred_df[p_columns].values, pred_df[t_columns].values):0.3f}\")\n",
    "\n",
    "# for i in range(len(t_columns)):\n",
    "#     prefix = \"AUC[overall] : \" if i == len(t_columns) - 1 else f\"AUC[C{i+1}]      : \"\n",
    "#     p = pred_df[p_columns[i]].values\n",
    "#     t = pred_df[t_columns[i]].values\n",
    "#     print(f\"{prefix}{auc(p, t):0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1573e8",
   "metadata": {
    "papermill": {
     "duration": 0.008751,
     "end_time": "2022-10-23T09:44:24.189151",
     "exception": false,
     "start_time": "2022-10-23T09:44:24.180400",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create Submission DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4817eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T22:13:33.205680Z",
     "start_time": "2023-07-12T22:13:33.175227Z"
    },
    "papermill": {
     "duration": 0.037569,
     "end_time": "2022-10-23T09:44:24.236041",
     "exception": false,
     "start_time": "2022-10-23T09:44:24.198472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ensemble_pred_dict = {}\n",
    "chunk_weight, slice_weight, fused_weight = 0.25, 0.25, 0.5\n",
    "for study_id in [*slice_prediction_dict]:\n",
    "    ensemble_pred_dict[study_id] = chunk_weight * chunk_prediction_dict[study_id] + \\\n",
    "                                    slice_weight * slice_prediction_dict[study_id] + \\\n",
    "                                    fused_weight * fused_prediction_dict[study_id]\n",
    "\n",
    "row_id_list = []\n",
    "fractured_list = []\n",
    "for k, v in ensemble_pred_dict.items():\n",
    "    for label_ind, label in enumerate(v[0]):\n",
    "        row_id = f\"{k}_C{label_ind + 1}\" if label_ind < 7 else f\"{k}_patient_overall\"\n",
    "        row_id_list.append(row_id)\n",
    "        fractured_list.append(label)\n",
    "        \n",
    "sub_df = pd.DataFrame({\"row_id\": row_id_list, \"fractured\": fractured_list})\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b14026",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T22:13:45.160978Z",
     "start_time": "2023-07-12T22:13:45.153314Z"
    },
    "papermill": {
     "duration": 1.137464,
     "end_time": "2022-10-23T09:44:25.383459",
     "exception": false,
     "start_time": "2022-10-23T09:44:24.245995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv(OUTPUT_FILE, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fa85ff",
   "metadata": {
    "papermill": {
     "duration": 0.020397,
     "end_time": "2022-10-23T09:44:25.414300",
     "exception": false,
     "start_time": "2022-10-23T09:44:25.393903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plot_volume(spine_map.numpy(), sagittal=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp39env",
   "language": "python",
   "name": "cp39env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 532.602317,
   "end_time": "2022-10-23T09:44:28.574509",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-10-23T09:35:35.972192",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
